{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import inventory_model\n",
    "import pandas as pd\n",
    "from evaluate import *\n",
    "from ppo_evaluate import ppo_evaluate\n",
    "import matplotlib as plt\n",
    "\n",
    "\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3 import DDPG\n",
    "from stable_baselines3.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wrapper for cont env, with DDPG, plot result for several steps\n",
    "def ddpg_eval_interval(p, L, t_t, n_iter, learning_rate=0.0003):\n",
    "    \n",
    "    ContCONFIG = {'h': 1, 'p': p, 'L': L, 'lambda': 1, 'action': 20.0}\n",
    "    cont_env = make_vec_env('inventory_cont_config_fix_model-v0', n_envs=1, env_kwargs=ContCONFIG)\n",
    "    print(\"Running DDPG w/: p=\", p, \", L=\",L)\n",
    "    n_actions = cont_env.action_space.shape[-1]\n",
    "    action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
    "    \n",
    "    cont_model = DDPG(\"MlpPolicy\", cont_env, action_noise=action_noise, verbose=1, gamma = 1)\n",
    "    \n",
    "    env_eval = make_vec_env('inventory_cont_config_fix_model-v0', n_envs=1, env_kwargs=ContCONFIG)\n",
    "    timesteps = 0\n",
    "    numiter = n_iter#test\n",
    "    res_mean_arr = []\n",
    "    res_std_arr = []\n",
    "\n",
    "    while(timesteps <= t_t):\n",
    "\n",
    "        cont_model.learn(total_timesteps=100)#\n",
    "        timesteps = timesteps + 100\n",
    "\n",
    "        res_mean, res_std = ppo_evaluate(cont_model, env_eval, numiter)\n",
    "        res_mean_arr.append(-res_mean)\n",
    "        res_std_arr.append(res_std)\n",
    "        print(res_mean_arr)\n",
    "    \n",
    "#     plt.pyplot.plot(res_mean_arr)\n",
    "\n",
    "    return res_mean_arr, res_std_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running DDPG w/: p= 99 , L= 100\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# listp = [0.25,1,4,9,39,99]\n",
    "# listL = [30,50,70,100]\n",
    "listp = [99]\n",
    "listL = [100]\n",
    "t_t = 10000\n",
    "n_iter = 1000\n",
    "learning_rate = 0.00001\n",
    "ddpg_res = pd.DataFrame(columns = ['p','L','res_mean', 'res_std'])\n",
    "\n",
    "for p in listp:\n",
    "    for L in listL:\n",
    "        res_mean, res_std = ddpg_eval_interval(p,L,t_t, n_iter, learning_rate)\n",
    "        ddpg_res = ddpg_res.append({'p': p, 'L':L, 'res_mean':min(res_mean), 'res_std': res_std[np.argmin(res_mean)]}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.pyplot.plot(res_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below is obsolete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ContCONFIG = {'h': 1, 'p': p, 'L': L, 'lambda': 1}\n",
    "cont_env = make_vec_env('inventory_cont_config_fix_model-v0', n_envs=1, env_kwargs=ContCONFIG)\n",
    "print(\"Running DDPG w/: p=\", p, \", L=\",L)\n",
    "n_actions = cont_env.action_space.shape[-1]\n",
    "action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
    "\n",
    "cont_model = DDPG(\"MlpPolicy\", cont_env, action_noise=action_noise, verbose=1, gamma = 1)\n",
    "cont_model.learn(total_timesteps=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
