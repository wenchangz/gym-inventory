{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "attended-immunology",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import inventory_model\n",
    "from evaluate import *\n",
    "from ppo_evaluate import ppo_evaluate\n",
    "\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "from stable_baselines3.common.env_util import make_vec_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increased-commodity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-active",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#continuous model try with cont action\n",
    "\n",
    "#env = make_vec_env('inventory_cont_model-v0', ContCONFIG = {'h': 1, 'p': 1, 'L': 10, 'lambda': 1}, n_envs=4)\n",
    "#how to set parameters???\n",
    "cont_env = make_vec_env('inventory_cont_model-v0', n_envs=8)\n",
    "cont_model = PPO(MlpPolicy, cont_env, verbose=1, gamma = 1)\n",
    "cont_model.learn(total_timesteps=200000)\n",
    "# fixed issue with vector, now action can be continuous\n",
    "\n",
    "#continuous evaluation\n",
    "cont_model.save(\"inv_cont_1\")\n",
    "trained_model = PPO.load(\"inv_cont_1\")\n",
    "env1 = gym.make('inventory_cont_model-v0')\n",
    "numiter = 50000\n",
    "res_mean, res_std = ppo_evaluate(trained_model, env1, numiter)\n",
    "print(-res_mean,'+/=',1.96*res_std/np.sqrt(5)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-lottery",
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# #continuous model try using config\n",
    "# listp = [0.25,1,4,9,39,99]\n",
    "# listL = [1,4,10,20,30,50,70,100]\n",
    "\n",
    "# for p in listp:\n",
    "#     for L in listL\n",
    "\n",
    "ContCONFIG = {'h': 1, 'p': 99, 'L': 100, 'lambda': 1}\n",
    "cont_env = gym.make('inventory_cont_config_model-v0', config=ContCONFIG)\n",
    "cont_model = PPO(MlpPolicy, cont_env, verbose=1, gamma = 1)\n",
    "cont_model.learn(total_timesteps=200000)\n",
    "\n",
    "#continuous evaluation\n",
    "cont_model.save(\"inv_cont_2\")\n",
    "trained_model = PPO.load(\"inv_cont_2\")\n",
    "env1 = gym.make('inventory_cont_config_model-v0', config=ContCONFIG)\n",
    "numiter = 50000\n",
    "res_mean, res_std = ppo_evaluate(trained_model, env1, numiter)\n",
    "print(-res_mean,'+/=',1.96*res_std/np.sqrt(5)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressive-celebrity",
   "metadata": {},
   "outputs": [],
   "source": [
    "#h=1,p=2,L=100,max_inventory=100,max_action=100,binomial(6,0.5)\n",
    "env = make_vec_env('inventory_model-v0', n_envs=4)\n",
    "model = PPO(MlpPolicy, env, verbose=1, gamma = 1)\n",
    "model.learn(total_timesteps=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valued-dimension",
   "metadata": {},
   "outputs": [],
   "source": [
    "#h=1,p=2,L=100,max_inventory=100,max_action=100\n",
    "model.save(\"inv_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rough-conference",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#from ppo_evaluate import ppo_evaluate\n",
    "\n",
    "#h=1,p=2,L=100,max_inventory=100\n",
    "trained_model = PPO.load(\"inv_1\")\n",
    "env1 = gym.make('inventory_model-v0')\n",
    "numiter = 200000\n",
    "res_mean, res_std = ppo_evaluate(trained_model, env1, numiter)\n",
    "print(-res_mean,'+/=',1.96*res_std/np.sqrt(5)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-light",
   "metadata": {},
   "outputs": [],
   "source": [
    "#h=1,p=99,L=1,max_inventory=100,max_action=100,binomial(6,0.5)\n",
    "env = make_vec_env('inventory_model-v0', n_envs=4)\n",
    "model = PPO(MlpPolicy, env, verbose=1, gamma = 1)\n",
    "model.learn(total_timesteps=1000000)\n",
    "model.save(\"inv_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "logical-cooler",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from ppo_evaluate import ppo_evaluate\n",
    "\n",
    "trained_model2 = PPO.load(\"inv_2\")\n",
    "env2 = gym.make('inventory_model-v0')\n",
    "numiter = 200000\n",
    "res_mean, res_std = ppo_evaluate(trained_model2, env2, numiter)\n",
    "print(-res_mean,'+/=',1.96*res_std/np.sqrt(5)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bigger-polymer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#h=1,p=99,L=1,max_inventory=100,max_action=6,binomial(6,0.5)\n",
    "env = make_vec_env('inventory_model-v0', n_envs=4)\n",
    "model = PPO(MlpPolicy, env, verbose=1, gamma = 1)\n",
    "model.learn(total_timesteps=1000000)\n",
    "model.save(\"inv_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innovative-swedish",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set action space to be small([0,1,2,3,4,5,6]) seems to get reasonable results...\n",
    "trained_model3 = PPO.load(\"inv_3\")\n",
    "env3 = gym.make('inventory_model-v0')\n",
    "numiter = 200000\n",
    "res_mean, res_std = ppo_evaluate(trained_model3, env3, numiter)\n",
    "print(-res_mean,'+/=',1.96*res_std/np.sqrt(5)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "prime-acceptance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 5302  |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 3     |\n",
      "|    total_timesteps | 16384 |\n",
      "------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 2255          |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 14            |\n",
      "|    total_timesteps      | 32768         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00019123404 |\n",
      "|    clip_fraction        | 0.00273       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.43         |\n",
      "|    explained_variance   | -0.000138     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.54e+06      |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.00131      |\n",
      "|    std                  | 1.02          |\n",
      "|    value_loss           | 2.95e+06      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1992         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 24           |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015378341 |\n",
      "|    clip_fraction        | 0.00136      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.43        |\n",
      "|    explained_variance   | -2.38e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.47e+06     |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00101     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 3.07e+06     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1799          |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 36            |\n",
      "|    total_timesteps      | 65536         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00085827534 |\n",
      "|    clip_fraction        | 0.00107       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.41         |\n",
      "|    explained_variance   | -4.77e-07     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.39e+06      |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.000943     |\n",
      "|    std                  | 0.985         |\n",
      "|    value_loss           | 3.09e+06      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1701         |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 48           |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008630308 |\n",
      "|    clip_fraction        | 0.00126      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | -1.07e-06    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.46e+06     |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00103     |\n",
      "|    std                  | 0.967        |\n",
      "|    value_loss           | 3.15e+06     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1678        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 58          |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001363972 |\n",
      "|    clip_fraction        | 0.00199     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | -3.58e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.53e+06    |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00118    |\n",
      "|    std                  | 0.958       |\n",
      "|    value_loss           | 3.14e+06    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1663         |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 68           |\n",
      "|    total_timesteps      | 114688       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005454725 |\n",
      "|    clip_fraction        | 0.000208     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.67e+06     |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.000634    |\n",
      "|    std                  | 0.959        |\n",
      "|    value_loss           | 3.12e+06     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1637         |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 80           |\n",
      "|    total_timesteps      | 131072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005909535 |\n",
      "|    clip_fraction        | 0.000171     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.45e+06     |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.000817    |\n",
      "|    std                  | 0.958        |\n",
      "|    value_loss           | 3.04e+06     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1611         |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 91           |\n",
      "|    total_timesteps      | 147456       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020842508 |\n",
      "|    clip_fraction        | 0.00607      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.65e+06     |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00165     |\n",
      "|    std                  | 0.956        |\n",
      "|    value_loss           | 3.14e+06     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1612         |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 101          |\n",
      "|    total_timesteps      | 163840       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011492837 |\n",
      "|    clip_fraction        | 0.00107      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.37        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.35e+06     |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00101     |\n",
      "|    std                  | 0.953        |\n",
      "|    value_loss           | 2.95e+06     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1601         |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 112          |\n",
      "|    total_timesteps      | 180224       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016890496 |\n",
      "|    clip_fraction        | 0.00173      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | 1.79e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.44e+06     |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.00116     |\n",
      "|    std                  | 0.964        |\n",
      "|    value_loss           | 3.01e+06     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1593         |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 123          |\n",
      "|    total_timesteps      | 196608       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005677969 |\n",
      "|    clip_fraction        | 0.00151      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.56e+06     |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00135     |\n",
      "|    std                  | 0.959        |\n",
      "|    value_loss           | 3.12e+06     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1588          |\n",
      "|    iterations           | 13            |\n",
      "|    time_elapsed         | 134           |\n",
      "|    total_timesteps      | 212992        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00076608453 |\n",
      "|    clip_fraction        | 0.00137       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.39         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.57e+06      |\n",
      "|    n_updates            | 120           |\n",
      "|    policy_gradient_loss | -0.00104      |\n",
      "|    std                  | 0.974         |\n",
      "|    value_loss           | 3.05e+06      |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7fe7ad088650>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ContCONFIG = {'h': 1, 'p': 99, 'L': 100, 'lambda': 1}\n",
    "cont_env = make_vec_env('inventory_cont_config_model-v0', n_envs=8, env_kwargs=ContCONFIG)\n",
    "cont_model = PPO(MlpPolicy, cont_env, verbose=1, gamma = 1)\n",
    "cont_model.learn(total_timesteps=200000)\n",
    "\n",
    "cont_model.save(\"inv_cont_2\")\n",
    "trained_model = PPO.load(\"inv_cont_2\")\n",
    "env1 = gym.make('inventory_cont_config_model-v0', config=ContCONFIG)\n",
    "numiter = 50000\n",
    "res_mean, res_std = ppo_evaluate(trained_model, env1, numiter)\n",
    "print(-res_mean,'+/=',1.96*res_std/np.sqrt(5)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
