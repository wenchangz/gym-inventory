{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import inventory_model\n",
    "import pandas as pd\n",
    "from evaluate import *\n",
    "from ppo_evaluate import ppo_evaluate\n",
    "import matplotlib as plt\n",
    "\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "from stable_baselines3.common.env_util import make_vec_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wrapper for cont env with PPO, plot result for several steps\n",
    "def ppo_eval_interval(p, L, t_t, n_iter, n_step, learning_rate=0.0003):\n",
    "    ContCONFIG = {'h': 1, 'p': p, 'L': L, 'lambda': 1}\n",
    "    cont_env = make_vec_env('inventory_cont_config_fix_model-v0', n_envs=4, env_kwargs=ContCONFIG)\n",
    "    print(\"Running PPO w/: p=\", p, \", L=\",L)\n",
    "    cont_model = PPO(MlpPolicy, cont_env, verbose=1, gamma = 1, \n",
    "                     learning_rate = learning_rate,use_sde = False, n_steps = n_step)\n",
    "    env_eval = make_vec_env('inventory_cont_config_fix_model-v0', n_envs=1, env_kwargs=ContCONFIG)\n",
    "    timesteps = 0\n",
    "    numiter = n_iter#test\n",
    "    res_mean_arr = []\n",
    "    res_std_arr = []\n",
    "\n",
    "    while(timesteps <= t_t):\n",
    "\n",
    "        cont_model.learn(total_timesteps=2*4*n_step-1)#each iteration has 8192 timesteps with n_env=4\n",
    "        timesteps = timesteps + 2*4*n_step\n",
    "\n",
    "        res_mean, res_std = ppo_evaluate(cont_model, env_eval, numiter)\n",
    "        res_mean_arr.append(-res_mean)\n",
    "        res_std_arr.append(res_std)\n",
    "        print(res_mean_arr)\n",
    "    \n",
    "#     plt.pyplot.plot(res_mean_arr)\n",
    "\n",
    "    return res_mean_arr, res_std_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PPO w/: p= 99 , L= 1\n",
      "Using cpu device\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 5559 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 0    |\n",
      "|    total_timesteps | 256  |\n",
      "-----------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 2372          |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 0             |\n",
      "|    total_timesteps      | 512           |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00046798936 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.42         |\n",
      "|    explained_variance   | 4.01e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.41e+05      |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.00151      |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 9.69e+05      |\n",
      "-------------------------------------------\n",
      "mean:  -59.17095490452924\n",
      "standard deviation: 4.697795445260998\n",
      "[59.17095490452924]\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 7891         |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 0            |\n",
      "|    total_timesteps      | 256          |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006591836 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | -0.00025     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.03e+05     |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.000677    |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 8.49e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 3103          |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 0             |\n",
      "|    total_timesteps      | 512           |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -0.0012424327 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.43         |\n",
      "|    explained_variance   | -0.000839     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.25e+05      |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.00184      |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 6.59e+05      |\n",
      "-------------------------------------------\n",
      "mean:  -56.71869272125831\n",
      "standard deviation: 4.0970656618709524\n",
      "[59.17095490452924, 56.71869272125831]\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 5591          |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 0             |\n",
      "|    total_timesteps      | 256           |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -6.047776e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.43         |\n",
      "|    explained_variance   | 0.000492      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.73e+05      |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | -0.000527     |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 6.92e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 2493          |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 0             |\n",
      "|    total_timesteps      | 512           |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -0.0017649904 |\n",
      "|    clip_fraction        | 0.000391      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.43         |\n",
      "|    explained_variance   | -0.00148      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4e+05         |\n",
      "|    n_updates            | 50            |\n",
      "|    policy_gradient_loss | -0.00359      |\n",
      "|    std                  | 1.02          |\n",
      "|    value_loss           | 7.55e+05      |\n",
      "-------------------------------------------\n",
      "mean:  -56.28169142733342\n",
      "standard deviation: 3.810245833163391\n",
      "[59.17095490452924, 56.71869272125831, 56.28169142733342]\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 6935         |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 0            |\n",
      "|    total_timesteps      | 256          |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012359668 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.44        |\n",
      "|    explained_variance   | -0.00149     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.66e+05     |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00105     |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 1.24e+06     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 2721          |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 0             |\n",
      "|    total_timesteps      | 512           |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -0.0019571492 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.44         |\n",
      "|    explained_variance   | -0.00302      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.18e+05      |\n",
      "|    n_updates            | 70            |\n",
      "|    policy_gradient_loss | -0.00164      |\n",
      "|    std                  | 1.02          |\n",
      "|    value_loss           | 8.91e+05      |\n",
      "-------------------------------------------\n",
      "mean:  -53.47460889015472\n",
      "standard deviation: 3.764841510828855\n",
      "[59.17095490452924, 56.71869272125831, 56.28169142733342, 53.47460889015472]\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 6700         |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 0            |\n",
      "|    total_timesteps      | 256          |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | -0.002044306 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.44        |\n",
      "|    explained_variance   | -0.00335     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.88e+05     |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00158     |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 7.93e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2573         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 0            |\n",
      "|    total_timesteps      | 512          |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012891025 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.44        |\n",
      "|    explained_variance   | -0.00075     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.81e+05     |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00231     |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 3.86e+05     |\n",
      "------------------------------------------\n",
      "mean:  -49.077869570682125\n",
      "standard deviation: 2.3385244261982145\n",
      "[59.17095490452924, 56.71869272125831, 56.28169142733342, 53.47460889015472, 49.077869570682125]\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 6275          |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 0             |\n",
      "|    total_timesteps      | 256           |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020509888 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.45         |\n",
      "|    explained_variance   | -0.00126      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.95e+05      |\n",
      "|    n_updates            | 100           |\n",
      "|    policy_gradient_loss | -0.00155      |\n",
      "|    std                  | 1.03          |\n",
      "|    value_loss           | 8.32e+05      |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 2797          |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 0             |\n",
      "|    total_timesteps      | 512           |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.1072337e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.45         |\n",
      "|    explained_variance   | -0.000667     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.46e+05      |\n",
      "|    n_updates            | 110           |\n",
      "|    policy_gradient_loss | -0.000456     |\n",
      "|    std                  | 1.04          |\n",
      "|    value_loss           | 5.81e+05      |\n",
      "-------------------------------------------\n",
      "mean:  -48.96946270537025\n",
      "standard deviation: 4.534465856099978\n",
      "[59.17095490452924, 56.71869272125831, 56.28169142733342, 53.47460889015472, 49.077869570682125, 48.96946270537025]\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 7545         |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 0            |\n",
      "|    total_timesteps      | 256          |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002861044 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.45        |\n",
      "|    explained_variance   | -0.0003      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.66e+05     |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.000356    |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 7.91e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 3038          |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 0             |\n",
      "|    total_timesteps      | 512           |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -0.0006517635 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.46         |\n",
      "|    explained_variance   | -0.00189      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.01e+05      |\n",
      "|    n_updates            | 130           |\n",
      "|    policy_gradient_loss | -0.000381     |\n",
      "|    std                  | 1.04          |\n",
      "|    value_loss           | 6.73e+05      |\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# listp = [0.25,1,4,9,39,99]\n",
    "# listL = [30,50,70,100]\n",
    "listp = [99]\n",
    "listL = [1]\n",
    "t_t = 100000\n",
    "n_iter = 1000\n",
    "# n_step = 8192\n",
    "learning_rate = 0.0003\n",
    "ppo_res = pd.DataFrame(columns = ['p','L','res_mean', 'res_std'])\n",
    "\n",
    "for p in listp:\n",
    "    for L in listL:\n",
    "        n_step = 64*L \n",
    "        res_mean, res_std = ppo_eval_interval(p,L,t_t, n_iter, n_step, learning_rate)\n",
    "        ppo_res = ppo_res.append({'p': p, 'L':L, 'res_mean':min(res_mean), 'res_std': res_std[np.argmin(res_mean)]}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.pyplot.plot(res_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below is obsolete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wrapper for continuous environment, obsolete\n",
    "def ppo_eval(p, L, t_t, n_iter, learning_rate=0.0003):\n",
    "    ContCONFIG = {'h': 1, 'p': p, 'L': L, 'lambda': 1}\n",
    "    cont_env = make_vec_env('inventory_cont_config_fix_model-v0', n_envs=4, env_kwargs=ContCONFIG)\n",
    "    print(\"Running PPO w/: p=\", p, \", L=\",L)\n",
    "    cont_model = PPO(MlpPolicy, cont_env, verbose=1, gamma = 1, learning_rate = learning_rate,use_sde = False)\n",
    "    cont_model.learn(total_timesteps=t_t)#testing 2000\n",
    "\n",
    "    cont_model.save(\"inv_cont_2\")\n",
    "    trained_model = PPO.load(\"inv_cont_2\")\n",
    "    env_eval = make_vec_env('inventory_cont_config_fix_model-v0', n_envs=1, env_kwargs=ContCONFIG)\n",
    "    numiter = n_iter#test\n",
    "    res_mean, res_std = ppo_evaluate(trained_model, env_eval, numiter)\n",
    "    print(-res_mean,'+/=',1.96*res_std/np.sqrt(5)) \n",
    "\n",
    "    return res_mean, res_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# listp = [0.25,1,4,9,39,99]\n",
    "# listL = [1,4,10,20,30,50,70,100]\n",
    "listp = [39]\n",
    "listL = [1]\n",
    "t_t = 200000\n",
    "n_iter = 100000\n",
    "learning_rate = 0.005\n",
    "ppo_res = pd.DataFrame(columns = ['p','L','res_mean', 'res_std'])\n",
    "\n",
    "for p in listp:\n",
    "    for L in listL:\n",
    "        res_mean, res_std = ppo_eval(p,L,t_t, n_iter, learning_rate)\n",
    "        ppo_res = ppo_res.append({'p': p, 'L':L, 'res_mean':res_mean, 'res_std': res_std}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#continuous model try with cont action\n",
    "\n",
    "# #env = make_vec_env('inventory_cont_model-v0', ContCONFIG = {'h': 1, 'p': 1, 'L': 10, 'lambda': 1}, n_envs=4)\n",
    "# #how to set parameters???\n",
    "# cont_env = make_vec_env('inventory_cont_model-v0', n_envs=8)\n",
    "# cont_model = PPO(MlpPolicy, cont_env, verbose=1, gamma = 1)\n",
    "# cont_model.learn(total_timesteps=200000)\n",
    "# # fixed issue with vector, now action can be continuous\n",
    "\n",
    "# #continuous evaluation\n",
    "# cont_model.save(\"inv_cont_1\")\n",
    "# trained_model = PPO.load(\"inv_cont_1\")\n",
    "# env1 = gym.make('inventory_cont_model-v0')\n",
    "# numiter = 50000\n",
    "# res_mean, res_std = ppo_evaluate(trained_model, env1, numiter)\n",
    "# print(-res_mean,'+/=',1.96*res_std/np.sqrt(5)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Discrete environment\n",
    "# #h=1,p=99,L=1,max_inventory=100,max_action=100,binomial(6,0.5)\n",
    "# env = make_vec_env('inventory_model-v0', n_envs=4)\n",
    "# model = PPO(MlpPolicy, env, verbose=1, gamma = 1)\n",
    "# model.learn(total_timesteps=1000000)\n",
    "# model.save(\"inv_2\")\n",
    "\n",
    "# trained_model2 = PPO.load(\"inv_2\")\n",
    "# env2 = gym.make('inventory_model-v0')\n",
    "# numiter = 200000\n",
    "# res_mean, res_std = ppo_evaluate(trained_model2, env2, numiter)\n",
    "# print(-res_mean,'+/=',1.96*res_std/np.sqrt(5)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Discrete environment 2\n",
    "#h=1,p=99,L=1,max_inventory=100,max_action=6,binomial(6,0.5)\n",
    "# env = make_vec_env('inventory_model-v0', n_envs=4)\n",
    "# model = PPO(MlpPolicy, env, verbose=1, gamma = 1)\n",
    "# model.learn(total_timesteps=1000000)\n",
    "# model.save(\"inv_3\")\n",
    "\n",
    "# #set action space to be small([0,1,2,3,4,5,6]) seems to get reasonable results...\n",
    "# trained_model3 = PPO.load(\"inv_3\")\n",
    "# env3 = gym.make('inventory_model-v0')\n",
    "# numiter = 200000\n",
    "# res_mean, res_std = ppo_evaluate(trained_model3, env3, numiter)\n",
    "# print(-res_mean,'+/=',1.96*res_std/np.sqrt(5)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
