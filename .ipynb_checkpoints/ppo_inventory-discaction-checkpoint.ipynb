{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import inventory_model\n",
    "import pandas as pd\n",
    "from evaluate import *\n",
    "from ppo_evaluate import ppo_evaluate\n",
    "import matplotlib as plt\n",
    "\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "from stable_baselines3.common.env_util import make_vec_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wrapper for cont env with PPO, plot result for several steps\n",
    "def ppo_eval_interval(p, L, t_t, n_iter, n_step, learning_rate=0.0003):\n",
    "    ContCONFIG = {'h': 1, 'p': p, 'L': L, 'lambda': 1}\n",
    "    cont_env = make_vec_env('inventory_cont_config_fix_model-v0', n_envs=4, env_kwargs=ContCONFIG)\n",
    "    print(\"Running PPO w/: p=\", p, \", L=\",L)\n",
    "    cont_model = PPO(MlpPolicy, cont_env, verbose=0, gamma = 1, \n",
    "                     learning_rate = learning_rate,use_sde = False, n_steps = n_step)\n",
    "    env_eval = make_vec_env('inventory_cont_config_fix_model-v0', n_envs=1, env_kwargs=ContCONFIG)\n",
    "    timesteps = 0\n",
    "    numiter = n_iter#test\n",
    "    res_mean_arr = []\n",
    "    res_std_arr = []\n",
    "\n",
    "    while(timesteps <= t_t):\n",
    "\n",
    "        cont_model.learn(total_timesteps=80000)#each iteration has 8192 timesteps with n_env=4\n",
    "        timesteps = timesteps + 81920\n",
    "\n",
    "        res_mean, res_std = ppo_evaluate(cont_model, env_eval, numiter)\n",
    "        res_mean_arr.append(-res_mean)\n",
    "        res_std_arr.append(res_std)\n",
    "        print(res_mean_arr)\n",
    "    \n",
    "#     plt.pyplot.plot(res_mean_arr)\n",
    "\n",
    "    return res_mean_arr, res_std_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PPO w/: p= 99 , L= 100\n",
      "mean:  -58.04941138781955\n",
      "standard deviation: 0.66463563398839\n",
      "[58.04941138781955]\n",
      "mean:  -59.7328797292736\n",
      "standard deviation: 0.8144734282656695\n",
      "[58.04941138781955, 59.7328797292736]\n",
      "mean:  -58.01557819269429\n",
      "standard deviation: 1.0676437648929045\n",
      "[58.04941138781955, 59.7328797292736, 58.01557819269429]\n",
      "mean:  -60.32070393351112\n",
      "standard deviation: 1.286467313569063\n",
      "[58.04941138781955, 59.7328797292736, 58.01557819269429, 60.32070393351112]\n",
      "mean:  -60.569489201588794\n",
      "standard deviation: 1.117775762982347\n",
      "[58.04941138781955, 59.7328797292736, 58.01557819269429, 60.32070393351112, 60.569489201588794]\n",
      "mean:  -60.65276940265333\n",
      "standard deviation: 0.529540706322553\n",
      "[58.04941138781955, 59.7328797292736, 58.01557819269429, 60.32070393351112, 60.569489201588794, 60.65276940265333]\n",
      "mean:  -62.49993316979699\n",
      "standard deviation: 1.2539343506635448\n",
      "[58.04941138781955, 59.7328797292736, 58.01557819269429, 60.32070393351112, 60.569489201588794, 60.65276940265333, 62.49993316979699]\n",
      "mean:  -64.67906053171096\n",
      "standard deviation: 0.8892468626649324\n",
      "[58.04941138781955, 59.7328797292736, 58.01557819269429, 60.32070393351112, 60.569489201588794, 60.65276940265333, 62.49993316979699, 64.67906053171096]\n",
      "mean:  -64.42526438969311\n",
      "standard deviation: 1.1621934787950525\n",
      "[58.04941138781955, 59.7328797292736, 58.01557819269429, 60.32070393351112, 60.569489201588794, 60.65276940265333, 62.49993316979699, 64.67906053171096, 64.42526438969311]\n",
      "mean:  -61.05026920164314\n",
      "standard deviation: 0.564564590391623\n",
      "[58.04941138781955, 59.7328797292736, 58.01557819269429, 60.32070393351112, 60.569489201588794, 60.65276940265333, 62.49993316979699, 64.67906053171096, 64.42526438969311, 61.05026920164314]\n",
      "mean:  -62.709092174996044\n",
      "standard deviation: 0.6922538034217375\n",
      "[58.04941138781955, 59.7328797292736, 58.01557819269429, 60.32070393351112, 60.569489201588794, 60.65276940265333, 62.49993316979699, 64.67906053171096, 64.42526438969311, 61.05026920164314, 62.709092174996044]\n",
      "mean:  -63.35369209829347\n",
      "standard deviation: 0.5228037873970832\n",
      "[58.04941138781955, 59.7328797292736, 58.01557819269429, 60.32070393351112, 60.569489201588794, 60.65276940265333, 62.49993316979699, 64.67906053171096, 64.42526438969311, 61.05026920164314, 62.709092174996044, 63.35369209829347]\n",
      "mean:  -64.71162548837071\n",
      "standard deviation: 0.6514176715335822\n",
      "[58.04941138781955, 59.7328797292736, 58.01557819269429, 60.32070393351112, 60.569489201588794, 60.65276940265333, 62.49993316979699, 64.67906053171096, 64.42526438969311, 61.05026920164314, 62.709092174996044, 63.35369209829347, 64.71162548837071]\n"
     ]
    }
   ],
   "source": [
    "# listp = [0.25,1,4,9,39,99]\n",
    "# listL = [30,50,70,100]\n",
    "listp = [99]\n",
    "listL = [100]\n",
    "t_t = 1000000\n",
    "n_iter = 10000\n",
    "n_step = 8192\n",
    "learning_rate = 0.0003\n",
    "ppo_res = pd.DataFrame(columns = ['p','L','res_mean', 'res_std'])\n",
    "\n",
    "for p in listp:\n",
    "    for L in listL:\n",
    "        res_mean, res_std = ppo_eval_interval(p,L,t_t, n_iter, n_step, learning_rate)\n",
    "        ppo_res = ppo_res.append({'p': p, 'L':L, 'res_mean':min(res_mean), 'res_std': res_std[np.argmin(res_mean)]}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p</th>\n",
       "      <th>L</th>\n",
       "      <th>res_mean</th>\n",
       "      <th>res_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>58.015578</td>\n",
       "      <td>1.067644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      p      L   res_mean   res_std\n",
       "0  99.0  100.0  58.015578  1.067644"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppo_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd255bc0070>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.pyplot.plot(res_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below is obsolete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wrapper for continuous environment, obsolete\n",
    "def ppo_eval(p, L, t_t, n_iter, learning_rate=0.0003):\n",
    "    ContCONFIG = {'h': 1, 'p': p, 'L': L, 'lambda': 1}\n",
    "    cont_env = make_vec_env('inventory_cont_config_fix_model-v0', n_envs=4, env_kwargs=ContCONFIG)\n",
    "    print(\"Running PPO w/: p=\", p, \", L=\",L)\n",
    "    cont_model = PPO(MlpPolicy, cont_env, verbose=1, gamma = 1, learning_rate = learning_rate,use_sde = False)\n",
    "    cont_model.learn(total_timesteps=t_t)#testing 2000\n",
    "\n",
    "    cont_model.save(\"inv_cont_2\")\n",
    "    trained_model = PPO.load(\"inv_cont_2\")\n",
    "    env_eval = make_vec_env('inventory_cont_config_fix_model-v0', n_envs=1, env_kwargs=ContCONFIG)\n",
    "    numiter = n_iter#test\n",
    "    res_mean, res_std = ppo_evaluate(trained_model, env_eval, numiter)\n",
    "    print(-res_mean,'+/=',1.96*res_std/np.sqrt(5)) \n",
    "\n",
    "    return res_mean, res_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PPO w/: p= 39 , L= 1\n",
      "Using cpu device\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 8028        |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001326405 |\n",
      "|    clip_fraction        | 0.00736     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.08e+05    |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0027     |\n",
      "|    std                  | 0.975       |\n",
      "|    value_loss           | 9.34e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3105        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010170783 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.43       |\n",
      "|    explained_variance   | 0.000163    |\n",
      "|    learning_rate        | 0.005       |\n",
      "|    loss                 | 1.08e+04    |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00991    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 9.62e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 2573       |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 9          |\n",
      "|    total_timesteps      | 24576      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.60280055 |\n",
      "|    clip_fraction        | 0.158      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.5       |\n",
      "|    explained_variance   | -1.55e-06  |\n",
      "|    learning_rate        | 0.005      |\n",
      "|    loss                 | 8.18e+03   |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.00118   |\n",
      "|    std                  | 1.15       |\n",
      "|    value_loss           | 6.92e+04   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 2298      |\n",
      "|    iterations           | 4         |\n",
      "|    time_elapsed         | 14        |\n",
      "|    total_timesteps      | 32768     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3622134 |\n",
      "|    clip_fraction        | 0.852     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.56     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.005     |\n",
      "|    loss                 | 5.43e+09  |\n",
      "|    n_updates            | 30        |\n",
      "|    policy_gradient_loss | 0.257     |\n",
      "|    std                  | 1.15      |\n",
      "|    value_loss           | 9.77e+09  |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2188         |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 18           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.868634e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.56        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.005        |\n",
      "|    loss                 | 4.03e+10     |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | 4e-06        |\n",
      "|    std                  | 1.15         |\n",
      "|    value_loss           | 8.08e+10     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2114         |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 23           |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.626564e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.56        |\n",
      "|    explained_variance   | -2.38e-07    |\n",
      "|    learning_rate        | 0.005        |\n",
      "|    loss                 | 1.15e+11     |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -6.44e-06    |\n",
      "|    std                  | 1.15         |\n",
      "|    value_loss           | 2.43e+11     |\n",
      "------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 2070           |\n",
      "|    iterations           | 7              |\n",
      "|    time_elapsed         | 27             |\n",
      "|    total_timesteps      | 57344          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -1.8142775e-05 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.56          |\n",
      "|    explained_variance   | -1.19e-07      |\n",
      "|    learning_rate        | 0.005          |\n",
      "|    loss                 | 2.44e+11       |\n",
      "|    n_updates            | 60             |\n",
      "|    policy_gradient_loss | -1.68e-05      |\n",
      "|    std                  | 1.15           |\n",
      "|    value_loss           | 4.96e+11       |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 2041          |\n",
      "|    iterations           | 8             |\n",
      "|    time_elapsed         | 32            |\n",
      "|    total_timesteps      | 65536         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.6965204e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.56         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.005         |\n",
      "|    loss                 | 4.05e+11      |\n",
      "|    n_updates            | 70            |\n",
      "|    policy_gradient_loss | -6.62e-06     |\n",
      "|    std                  | 1.15          |\n",
      "|    value_loss           | 8.36e+11      |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 2016           |\n",
      "|    iterations           | 9              |\n",
      "|    time_elapsed         | 36             |\n",
      "|    total_timesteps      | 73728          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -4.6222587e-05 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.56          |\n",
      "|    explained_variance   | -1.19e-07      |\n",
      "|    learning_rate        | 0.005          |\n",
      "|    loss                 | 6.41e+11       |\n",
      "|    n_updates            | 80             |\n",
      "|    policy_gradient_loss | -2e-05         |\n",
      "|    std                  | 1.15           |\n",
      "|    value_loss           | 1.27e+12       |\n",
      "--------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1995         |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 41           |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | -9.49204e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.56        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.005        |\n",
      "|    loss                 | 8.87e+11     |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -1.29e-08    |\n",
      "|    std                  | 1.15         |\n",
      "|    value_loss           | 1.79e+12     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1978         |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 45           |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.000324e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.56        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.005        |\n",
      "|    loss                 | 1.21e+12     |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.000113    |\n",
      "|    std                  | 1.15         |\n",
      "|    value_loss           | 2.4e+12      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1951          |\n",
      "|    iterations           | 12            |\n",
      "|    time_elapsed         | 50            |\n",
      "|    total_timesteps      | 98304         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1588811e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.56         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.005         |\n",
      "|    loss                 | 1.56e+12      |\n",
      "|    n_updates            | 110           |\n",
      "|    policy_gradient_loss | -1.04e-07     |\n",
      "|    std                  | 1.15          |\n",
      "|    value_loss           | 3.1e+12       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1935          |\n",
      "|    iterations           | 13            |\n",
      "|    time_elapsed         | 55            |\n",
      "|    total_timesteps      | 106496        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1466109e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.56         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.005         |\n",
      "|    loss                 | 1.94e+12      |\n",
      "|    n_updates            | 120           |\n",
      "|    policy_gradient_loss | 1.81e-06      |\n",
      "|    std                  | 1.16          |\n",
      "|    value_loss           | 3.89e+12      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1920         |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 59           |\n",
      "|    total_timesteps      | 114688       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.086697e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.56        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.005        |\n",
      "|    loss                 | 2.41e+12     |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -2.44e-06    |\n",
      "|    std                  | 1.16         |\n",
      "|    value_loss           | 4.76e+12     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1896          |\n",
      "|    iterations           | 15            |\n",
      "|    time_elapsed         | 64            |\n",
      "|    total_timesteps      | 122880        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.4442037e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.56         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.005         |\n",
      "|    loss                 | 2.87e+12      |\n",
      "|    n_updates            | 140           |\n",
      "|    policy_gradient_loss | -2.77e-07     |\n",
      "|    std                  | 1.16          |\n",
      "|    value_loss           | 5.73e+12      |\n",
      "-------------------------------------------\n",
      "---------------------------------------------\n",
      "| time/                   |                 |\n",
      "|    fps                  | 1883            |\n",
      "|    iterations           | 16              |\n",
      "|    time_elapsed         | 69              |\n",
      "|    total_timesteps      | 131072          |\n",
      "| train/                  |                 |\n",
      "|    approx_kl            | -1.16198935e-05 |\n",
      "|    clip_fraction        | 0               |\n",
      "|    clip_range           | 0.2             |\n",
      "|    entropy_loss         | -1.56           |\n",
      "|    explained_variance   | -1.19e-07       |\n",
      "|    learning_rate        | 0.005           |\n",
      "|    loss                 | 3.42e+12        |\n",
      "|    n_updates            | 150             |\n",
      "|    policy_gradient_loss | -0.000266       |\n",
      "|    std                  | 1.16            |\n",
      "|    value_loss           | 6.79e+12        |\n",
      "---------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b1d84fe3ecd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlistp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mL\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlistL\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mres_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mppo_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mppo_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mppo_res\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'p'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'L'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'res_mean'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mres_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'res_std'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres_std\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-8e450b44397a>\u001b[0m in \u001b[0;36mppo_eval\u001b[0;34m(p, L, t_t, n_iter, learning_rate)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Running PPO w/: p=\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\", L=\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcont_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPPO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMlpPolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcont_env\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muse_sde\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mcont_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#testing 2000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mcont_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inv_cont_2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/stable_baselines3/ppo/ppo.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    278\u001b[0m     ) -> \"PPO\":\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         return super(PPO, self).learn(\n\u001b[0m\u001b[1;32m    281\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    245\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_training_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/stable_baselines3/ppo/ppo.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    234\u001b[0m                 \u001b[0;31m# Optimization step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m                 \u001b[0;31m# Clip grad norm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# listp = [0.25,1,4,9,39,99]\n",
    "# listL = [1,4,10,20,30,50,70,100]\n",
    "listp = [39]\n",
    "listL = [1]\n",
    "t_t = 200000\n",
    "n_iter = 100000\n",
    "learning_rate = 0.005\n",
    "ppo_res = pd.DataFrame(columns = ['p','L','res_mean', 'res_std'])\n",
    "\n",
    "for p in listp:\n",
    "    for L in listL:\n",
    "        res_mean, res_std = ppo_eval(p,L,t_t, n_iter, learning_rate)\n",
    "        ppo_res = ppo_res.append({'p': p, 'L':L, 'res_mean':res_mean, 'res_std': res_std}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#continuous model try with cont action\n",
    "\n",
    "# #env = make_vec_env('inventory_cont_model-v0', ContCONFIG = {'h': 1, 'p': 1, 'L': 10, 'lambda': 1}, n_envs=4)\n",
    "# #how to set parameters???\n",
    "# cont_env = make_vec_env('inventory_cont_model-v0', n_envs=8)\n",
    "# cont_model = PPO(MlpPolicy, cont_env, verbose=1, gamma = 1)\n",
    "# cont_model.learn(total_timesteps=200000)\n",
    "# # fixed issue with vector, now action can be continuous\n",
    "\n",
    "# #continuous evaluation\n",
    "# cont_model.save(\"inv_cont_1\")\n",
    "# trained_model = PPO.load(\"inv_cont_1\")\n",
    "# env1 = gym.make('inventory_cont_model-v0')\n",
    "# numiter = 50000\n",
    "# res_mean, res_std = ppo_evaluate(trained_model, env1, numiter)\n",
    "# print(-res_mean,'+/=',1.96*res_std/np.sqrt(5)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Discrete environment\n",
    "# #h=1,p=99,L=1,max_inventory=100,max_action=100,binomial(6,0.5)\n",
    "# env = make_vec_env('inventory_model-v0', n_envs=4)\n",
    "# model = PPO(MlpPolicy, env, verbose=1, gamma = 1)\n",
    "# model.learn(total_timesteps=1000000)\n",
    "# model.save(\"inv_2\")\n",
    "\n",
    "# trained_model2 = PPO.load(\"inv_2\")\n",
    "# env2 = gym.make('inventory_model-v0')\n",
    "# numiter = 200000\n",
    "# res_mean, res_std = ppo_evaluate(trained_model2, env2, numiter)\n",
    "# print(-res_mean,'+/=',1.96*res_std/np.sqrt(5)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Discrete environment 2\n",
    "#h=1,p=99,L=1,max_inventory=100,max_action=6,binomial(6,0.5)\n",
    "# env = make_vec_env('inventory_model-v0', n_envs=4)\n",
    "# model = PPO(MlpPolicy, env, verbose=1, gamma = 1)\n",
    "# model.learn(total_timesteps=1000000)\n",
    "# model.save(\"inv_3\")\n",
    "\n",
    "# #set action space to be small([0,1,2,3,4,5,6]) seems to get reasonable results...\n",
    "# trained_model3 = PPO.load(\"inv_3\")\n",
    "# env3 = gym.make('inventory_model-v0')\n",
    "# numiter = 200000\n",
    "# res_mean, res_std = ppo_evaluate(trained_model3, env3, numiter)\n",
    "# print(-res_mean,'+/=',1.96*res_std/np.sqrt(5)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
